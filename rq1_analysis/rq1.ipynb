{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# %pip install pandas\n",
    "# %pip install numpy\n",
    "# %pip install matplotlib\n",
    "# %pip install seaborn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Test dependency detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from pathlib import Path\n",
    "# AST result repository\n",
    "file_directory = \"/work/output/commit/temp-commit/commit_info_consul_k8s/consul-k8s\"\n",
    "# dependency output location\n",
    "result_path = Path('/work/output/commit/dependency-output/out_consul_k8s.csv')\n",
    "files = [f for f in listdir(file_directory) if not f.endswith(\"_error.csv\")]\n",
    "error_file = [f for f in listdir(file_directory) if f.endswith(\"_error.csv\")]\n",
    "\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "temp_list = []\n",
    "\n",
    "for file in error_file:\n",
    "    temp = pd.read_csv(file_directory + \"/\" + file)\n",
    "    for line in temp.iterrows():\n",
    "        if \"no buildable Go source files\" not in line[1][\"error_message\"] and line[1][\"package_path\"]:\n",
    "            temp_list.append(line[1])\n",
    "\n",
    "error_package = pd.DataFrame(temp_list)\n",
    "error_package[\"repo_name\"] = error_package[\"package_path\"].apply(lambda x: x.split(\"/\")[4])\n",
    "error_package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "df = pd.DataFrame()\n",
    "\n",
    "for file in files:\n",
    "    temp = pd.read_csv(file_directory + \"/\" + file)\n",
    "    temp['contain_terratest'] = temp['contain_terratest'].astype(bool)\n",
    "    repo_name = file.split(\".\")[0].split(\"_\")[0]\n",
    "    temp['repo_name'] = repo_name\n",
    "    df = pd.concat([df, temp], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Dependency:\n",
    "    func_name: str\n",
    "    package_name: str\n",
    "\n",
    "    def __init__(self, func_name, package_name, previous_func=None, pos=None):\n",
    "        self.func_name = func_name\n",
    "        self.package_name = package_name\n",
    "        self.previous_func = previous_func\n",
    "        self.pos = pos\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return self.func_name == other.func_name and self.package_name == other.package_name\n",
    "\n",
    "    def __str__(self):\n",
    "        if self.previous_func is None:\n",
    "            return self.func_name + \" \" + self.package_name\n",
    "        else:\n",
    "            return self.func_name + \" \" + self.package_name + \" \" + self.previous_func\n",
    "\n",
    "def find_repo_with_test_cases(temp_df):\n",
    "    repo_dict = {}\n",
    "    for i in temp_df.iterrows():\n",
    "        if type(i[1]['func_decl_name']) == float:\n",
    "            continue\n",
    "        if i[1]['func_decl_name'].startswith('Test') or i[1]['func_decl_name'] == 'Describe':\n",
    "            node = Dependency(i[1]['func_decl_name'], i[1]['package_name'], pos=i[1]['pos'])\n",
    "            if i[1]['repo_name'] not in repo_dict:\n",
    "                repo_dict[i[1]['repo_name']] = [node]\n",
    "            elif node not in repo_dict[i[1]['repo_name']]:\n",
    "                repo_dict[i[1]['repo_name']].append(node)\n",
    "    return repo_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from queue import Queue\n",
    "\n",
    "# Find chain dependency with function call\n",
    "def find_chain_dependency(repo_df, current_func_name, package_name, repo_name, pos):\n",
    "    func_df = pd.DataFrame()\n",
    "    adj_list = Queue()\n",
    "    for dependency in find_called_func(repo_df, current_func_name, package_name, pos):\n",
    "        adj_list.put(dependency)\n",
    "    travelled_list = []\n",
    "    while not adj_list.empty():\n",
    "        node = adj_list.get()\n",
    "        node_func_name = node.func_name\n",
    "        node_package_name = node.package_name\n",
    "        if node not in travelled_list:\n",
    "            temp_df = pd.DataFrame([[repo_name, node_func_name, node_package_name]], columns=['repo_name', 'func_name', 'package_name'])\n",
    "            func_df = pd.concat([func_df, temp_df], ignore_index=True)\n",
    "            if repo_name in node_package_name or not 'github' in node_package_name:\n",
    "                for next_node in find_called_func(repo_df, node_func_name, node_package_name, None):\n",
    "                    next_node.previous_func = node_func_name\n",
    "                    adj_list.put(next_node)\n",
    "            travelled_list.append(node)\n",
    "    return func_df\n",
    "\n",
    "\n",
    "def find_called_func(repo_df, func_name, package_name, pos):\n",
    "    dependency_list = []\n",
    "    if pos is not None:\n",
    "        temp_df = repo_df[(repo_df['func_decl_name'] == func_name) & (repo_df['package_name'] == (package_name.split(\"/\")[-1])) & (repo_df['pos'] == pos)]\n",
    "    else:\n",
    "        temp_df = repo_df[(repo_df['func_decl_name'] == func_name) & (repo_df['package_name'] == (package_name.split(\"/\")[-1]))]\n",
    "    for i in temp_df.iterrows():\n",
    "        dependency_list.append(Dependency(i[1]['func_name'], i[1]['module_path']))\n",
    "\n",
    "    return dependency_list\n",
    "\n",
    "def swap_columns(df, col1, col2):\n",
    "    col_list = list(df.columns)\n",
    "    x, y = col_list.index(col1), col_list.index(col2)\n",
    "    col_list[y], col_list[x] = col_list[x], col_list[y]\n",
    "    df = df[col_list]\n",
    "    return df\n",
    "\n",
    "def detect_dependency_df(inpt):\n",
    "    repo_df = inpt[0]\n",
    "    func_name = inpt[1]\n",
    "    package_name = inpt[2]\n",
    "    repo_name = inpt[3]\n",
    "    pos = inpt[4]\n",
    "    result = find_chain_dependency(repo_df, func_name, package_name, repo_name, pos)\n",
    "    result['func_decl_name'] = func_name\n",
    "    result['func_decl_package_name'] = package_name\n",
    "    result['pos'] = pos\n",
    "    result = swap_columns(result, 'func_decl_name', 'func_name')\n",
    "    result = swap_columns(result, 'func_decl_package_name', 'package_name')\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "is_executing": true
   },
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import multiprocessing as mp\n",
    "input_list = []\n",
    "result = pd.DataFrame()\n",
    "\n",
    "repo_list = pd.DataFrame([file.split('_')[0] for file in files])\n",
    "repo_list.drop_duplicates(inplace=True)\n",
    "repo_list\n",
    "for i, repo in repo_list.iterrows():\n",
    "    file_list = [f for f in listdir(file_directory) if (not f.endswith(\"_error.csv\")) and (f.startswith(repo[0]))]\n",
    "    repo_df = pd.DataFrame()\n",
    "    for file in file_list:\n",
    "        temp_df = pd.read_csv(file_directory + '/' + file)\n",
    "        temp_df['contain_terratest'] = temp_df['contain_terratest'].astype(bool)\n",
    "        repo_name = file.split(\".\")[0].split(\"_\")[0]\n",
    "        temp_df['repo_name'] = repo_name\n",
    "        repo_df = pd.concat([repo_df, temp_df], ignore_index=True)\n",
    "    repo_name_with_test = find_repo_with_test_cases(repo_df)\n",
    "    if repo[0] in repo_name_with_test:\n",
    "        for func in repo_name_with_test[repo[0]]:\n",
    "            input_list.append([repo_df, func.func_name, func.package_name, repo[0], func.pos])\n",
    "    else:\n",
    "        print(repo[0] + \" does not have test cases\")\n",
    "    detect_dependency_df(input_list[0])\n",
    "    with mp.Pool(50) as pool:\n",
    "        result = pool.map(detect_dependency_df, input_list)\n",
    "    result = pd.concat(result, ignore_index=True)\n",
    "    result.to_csv(result_path)\n",
    "    print(repo[0] + \" is done\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# ------------------------------------------------------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# RQ1: Test cases information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T11:59:33.501887Z",
     "start_time": "2023-08-01T11:59:25.580914Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Repository dependency data that store in csv format\n",
    "new_df = pd.read_csv('')\n",
    "new_df['contain_terratest'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest')\n",
    "new_df = new_df[new_df['repo_name'] != 'gruntwork-io---terratest']\n",
    "\n",
    "terratest_integration_func = pd.read_csv('terratest_integration_func.csv')\n",
    "terratest_func_list = []\n",
    "\n",
    "for i, row in terratest_integration_func.iterrows():\n",
    "    terratest_func_list.append((row['func_name'], row['package_name']))\n",
    "new_df['is_integrate'] = new_df.apply(lambda row: ((row['func_name'], row['package_name']) in terratest_func_list) or (row['package_name'] in ['github.com/gruntwork-io/terratest/modules/azure', 'github.com/gruntwork-io/terratest/modules/gcp', 'github.com/gruntwork-io/terratest/modules/aws']), axis=1)\n",
    "\n",
    "new_df['is_helm'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/helm')\n",
    "new_df['is_aws'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/aws')\n",
    "new_df['is_gcp'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/gcp')\n",
    "new_df['is_azure'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/azure')\n",
    "new_df['is_terraform'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/terraform')\n",
    "new_df['is_k8s'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/k8s')\n",
    "new_df['is_docker'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/docker')\n",
    "new_df['is_packer'] = new_df['package_name'].str.contains('github.com/gruntwork-io/terratest/modules/packer')\n",
    "\n",
    "repo_with_func_and_count_terratest = new_df.groupby(['repo_name', 'func_decl_name', 'pos']).agg({'is_integrate':'sum' ,'contain_terratest':'sum', 'is_aws':'sum', 'is_gcp':'sum', 'is_azure':'sum', 'is_terraform':'sum', 'is_k8s':'sum', 'is_docker':'sum', 'is_packer':'sum', 'is_helm':'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T11:59:37.761602Z",
     "start_time": "2023-08-01T11:59:35.633070Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_list = []\n",
    "result_df = pd.DataFrame()\n",
    "\n",
    "for name, group in new_df.groupby(['repo_name', 'func_decl_name', 'pos']):\n",
    "    if (group['func_name'] == \"Describe\").any() and name[1] == \"Describe\":\n",
    "        remove_list.append((name[0], name[1], name[2]))\n",
    "        \n",
    "\n",
    "repo_with_func_and_count_terratest = repo_with_func_and_count_terratest[~repo_with_func_and_count_terratest[['repo_name', 'func_decl_name', 'pos']].apply(tuple,1).isin(remove_list)]\n",
    "result_df[\"num_test\"] = repo_with_func_and_count_terratest.groupby('repo_name').size()\n",
    "result_df[\"num_test\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['func_decl_name'].str.startswith('Test')\n",
    "].groupby('repo_name').size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df.index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result_df.median())\n",
    "result_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_result_df = result_df.copy()\n",
    "temp_result_df = temp_result_df.reset_index()\n",
    "# temp_result_df.to_csv('repo_with_test_count.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T11:59:37.887965Z",
     "start_time": "2023-08-01T11:59:37.769856Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df[\"num_test_terratest\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['contain_terratest'] > 0].groupby('repo_name').size()\n",
    "\n",
    "result_df[\"num_integration_test\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_integrate'] > 0].groupby('repo_name').size()\n",
    "\n",
    "result_df['num_helm'] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_helm'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_aws\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_aws'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_gcp\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_gcp'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_azure\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_azure'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_terraform\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_terraform'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_k8s\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_k8s'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_docker\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_docker'] > 0].groupby('repo_name').size()\n",
    "result_df[\"num_packer\"] = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['is_packer'] > 0].groupby('repo_name').size()\n",
    "# result_df = result_df[result_df['repo_name'] != 'terratest']\n",
    "\n",
    "result_df = result_df.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_cases_df = pd.DataFrame(columns=['module', 'num_test'])\n",
    "temp_df = pd.DataFrame([[\"helm\", result_df['num_helm'].sum()]], columns=['module', 'num_test'])\n",
    "test_cases_df = pd.concat([test_cases_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"kubernetes\", result_df['num_k8s'].sum()]], columns=['module', 'num_test'])\n",
    "test_cases_df = pd.concat([test_cases_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"terraform\", result_df['num_terraform'].sum()]], columns=['module', 'num_test'])\n",
    "test_cases_df = pd.concat([test_cases_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"gcp\", result_df['num_gcp'].sum()]], columns=['module', 'num_test'])\n",
    "test_cases_df = pd.concat([test_cases_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"docker\", result_df['num_docker'].sum()]], columns=['module', 'num_test'])\n",
    "test_cases_df = pd.concat([test_cases_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"aws\", result_df['num_aws'].sum()]], columns=['module', 'num_test'])\n",
    "test_cases_df = pd.concat([test_cases_df, temp_df], ignore_index=True)\n",
    "test_cases_df = test_cases_df.set_index('module')\n",
    "test_cases_df = test_cases_df.sort_values(by=['num_test'], ascending=False)\n",
    "\n",
    "sns.set(font_scale=3)\n",
    "plt.figure(figsize=(16,9))\n",
    "ax = sns.barplot(x=test_cases_df.index, y=test_cases_df['num_test'])\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set(xlabel=\"Terratest module\", ylabel='Number of Test Cases')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
    "plt.savefig('/home/plot/count_test_cases.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_repo_df = pd.DataFrame(columns=['module', 'num_repo'])\n",
    "\n",
    "temp_df = pd.DataFrame([[\"helm\", result_df[result_df['num_helm'] > 0]['num_helm'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"kubernetes\", result_df[result_df['num_k8s'] > 0]['num_k8s'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"gcp\", result_df[result_df['num_gcp'] > 0]['num_gcp'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"aws\", result_df[result_df['num_aws'] > 0]['num_aws'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"azure\", result_df[result_df['num_azure'] > 0]['num_azure'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"terraform\", result_df[result_df['num_terraform'] > 0]['num_terraform'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"docker\", result_df[result_df['num_docker'] > 0]['num_docker'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "temp_df = pd.DataFrame([[\"packer\", result_df[result_df['num_packer'] > 0]['num_packer'].count()]], columns=['module', 'num_repo'])\n",
    "count_repo_df = pd.concat([count_repo_df, temp_df], ignore_index=True)\n",
    "count_repo_df = count_repo_df.set_index('module')\n",
    "count_repo_df = count_repo_df.sort_values(by=['num_repo'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=3)\n",
    "plt.figure(figsize=(16,9))\n",
    "ax = sns.barplot(x=count_repo_df.index, y=count_repo_df['num_repo'])\n",
    "ax.bar_label(ax.containers[0])\n",
    "ax.set(xlabel=\"Terratest module\", ylabel='Number of Repositories')\n",
    "ax.set_xticklabels(ax.get_xticklabels(),rotation=30)\n",
    "plt.savefig('/home/plot/count_repositories.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-08-01T12:01:34.076644Z",
     "start_time": "2023-08-01T12:01:33.911185Z"
    },
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "# plot = result_df.boxplot(column=['num_test'], showmeans=True)\n",
    "sns.set(font_scale=2.5)\n",
    "plt.figure(figsize=(9,9))\n",
    "box_plot = sns.boxplot(y='num_test', data=result_df)\n",
    "box_plot.set(ylabel='Number of Test Cases')\n",
    "median = result_df['num_test'].median()\n",
    "vertical_offset = median * 0.1\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick,median + vertical_offset,median, \n",
    "            horizontalalignment='center',size='x-small',color='w',weight='semibold')\n",
    "plt.savefig('/home/plot/rq1_num_test.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['num_test'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot = result_df.boxplot(column=['num_test_terratest'], showmeans=True)\n",
    "sns.set(font_scale=2.5)\n",
    "plt.figure(figsize=(9,9))\n",
    "box_plot = sns.boxplot(y='num_test_terratest', data=result_df)\n",
    "median = result_df['num_test_terratest'].median()\n",
    "box_plot.set(ylabel='Number of Test Cases')\n",
    "vertical_offset = median * 0.1\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick,median + vertical_offset,median, \n",
    "            horizontalalignment='center',size='x-small',color='w',weight='semibold')\n",
    "plt.savefig('/home/plot/rq1_num_test_terratest.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['num_test_terratest'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# result_df.boxplot(column=['num_integration_test'])\n",
    "sns.set(font_scale=2.5)\n",
    "plt.figure(figsize=(9,9))\n",
    "box_plot = sns.boxplot(y='num_integration_test', data=result_df)\n",
    "median = result_df['num_integration_test'].median()\n",
    "box_plot.set(ylabel='Number of Test Cases')\n",
    "vertical_offset = median * 0.1\n",
    "for xtick in box_plot.get_xticks():\n",
    "    box_plot.text(xtick,median + vertical_offset,median, \n",
    "            horizontalalignment='center',size='x-small',color='w',weight='semibold')\n",
    "plt.savefig('/home/plot/rq1_num_integration_test.pdf', format='pdf', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df['num_integration_test'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_test'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_test_terratest'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_integration_test'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_aws'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_gcp'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_azure'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_terraform'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_k8s'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_docker'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "result_df['num_packer'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Detect Test Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detect_test = repo_with_func_and_count_terratest[repo_with_func_and_count_terratest['contain_terratest'] > 0]\n",
    "detect_test = detect_test[['repo_name', 'func_decl_name', 'pos']]\n",
    "detect_test = detect_test.drop_duplicates()\n",
    "detect_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "\n",
    "def get_df_from_repo_name(repo_name):\n",
    "    file_directory = \"/home/repo-output\"\n",
    "    file_list = [f for f in listdir(file_directory) if not f.endswith(\"_error.csv\")]\n",
    "    \n",
    "    result_df = pd.DataFrame()\n",
    "    for file in file_list:\n",
    "        if repo_name in file:\n",
    "            temp_df = pd.read_csv(file_directory + \"/\" + file)\n",
    "            result_df = pd.concat([result_df, temp_df])\n",
    "    return result_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_repo_test = detect_test.groupby('repo_name')\n",
    "\n",
    "repo_test = pd.DataFrame()\n",
    "repo_commit_hash = pd.read_csv('/home/commit_hash.csv')\n",
    "for name, group in grouped_repo_test:\n",
    "    temp = get_df_from_repo_name(name)\n",
    "    temp = temp[['file_name', 'package_name', 'func_decl_name', 'pos']]\n",
    "    temp = temp.drop_duplicates()\n",
    "    temp['repo_name'] = name\n",
    "    new_df = pd.merge(group, temp, on=['repo_name', 'func_decl_name', 'pos'], how='left')\n",
    "    new_df = pd.merge(new_df, repo_commit_hash, on=['repo_name'], how='left')\n",
    "    repo_test = pd.concat([repo_test, new_df], ignore_index=True)\n",
    "    \n",
    "repo_test = repo_test.drop_duplicates()\n",
    "repo_test['github_path'] = list(repo_test['file_name'].str.split('/'))\n",
    "repo_test['github_path'] = list(repo_test['github_path'].str[1:])\n",
    "repo_test['github_path'] = 'github.com/' + repo_test['repo_name'].str.replace(\"---\", \"/\") + \"/tree/\" + repo_test['commit_sha'] + \"/\" + repo_test['github_path'].apply(lambda x: '/'.join(x))\n",
    "repo_test.to_csv('/home/repo_test_data_set.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
